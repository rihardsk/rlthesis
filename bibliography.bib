% This file was created with JabRef 2.9.2.
% Encoding: UTF8

@INCOLLECTION{Freivalds1981,
  author = {Freivalds, Rūsiņš},
  editor = {Gruska, Jozef and Chytil, Michal},
  title = {Probabilistic two-way machines},
  booktitle = {Mathematical Foundations of Computer Science 1981},
  year = {1981},
  volume = {118},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  isbn = {978-3-540-10856-6},
  pages = {33-45},
  doi = {10.1007/3-540-10856-4_72},
  url = {http://dx.doi.org/10.1007/3-540-10856-4_72}
}

@ARTICLE{Bel,
    author = "Richard Bellman",
     title = "A Markovian Decision Process",
   journal = "Indiana Univ. Math. J.",
  fjournal = "Indiana University Mathematics Journal",
    volume = 6,
      year = 1957,
     issue = 4,
     pages = "679--684",
      issn = "0022-2518",
     coden = "IUMJAB",
   mrclass = "",
}

@BOOK{Barto,
  title = "Reinforcement learning: An introduction",
  author = "Barto, Andrew G",
  year = 1998,
  publisher = "MIT press",
}

@article{Hendler1990ai,
  title={AI planning: Systems and techniques},
  author={Hendler, James A and Tate, Austin and Drummond, Mark},
  journal={AI magazine},
  volume={11},
  number={2},
  pages={61},
  year={1990}
}

@incollection{Otterlo,
year={2012},
isbn={978-3-642-27644-6},
booktitle={Reinforcement Learning},
volume={12},
series={Adaptation, Learning, and Optimization},
editor={Wiering, Marco and van Otterlo, Martijn},
doi={10.1007/978-3-642-27645-3_1},
title={Reinforcement Learning and Markov Decision Processes},
url={http://dx.doi.org/10.1007/978-3-642-27645-3_1},
publisher={Springer Berlin Heidelberg},
author={van Otterlo, Martijn and Wiering, Marco},
pages={3-42},
language={English}
}

@article{koenig2002interaction,
  title={The interaction of representations and planning objectives for decision-theoretic planning tasks},
  author={Koenig, Sven and Liu, Yaxin},
  journal={Journal of Experimental \& Theoretical Artificial Intelligence},
  volume={14},
  number={4},
  pages={303--326},
  year={2002},
  publisher={Taylor \& Francis}
}

@inproceedings{Hasselt2007,
  title={Reinforcement learning in continuous action spaces},
  author={Van Hasselt, Hado and Wiering, Marco A},
  booktitle={Approximate Dynamic Programming and Reinforcement Learning, 2007. ADPRL 2007. IEEE International Symposium on},
  pages={272--279},
  year={2007},
  organization={IEEE}
}

@incollection{Hasselt2012,
  title={Reinforcement learning in continuous state and action spaces},
  author={Van Hasselt, Hado},
  booktitle={Reinforcement Learning},
  pages={207--251},
  year={2012},
  publisher={Springer}
}

@article{nguyen2011model,
  title={Model learning for robot control: a survey},
  author={Nguyen-Tuong, Duy and Peters, Jan},
  journal={Cognitive processing},
  volume={12},
  number={4},
  pages={319--340},
  year={2011},
  publisher={Springer}
}

@article{tesauro1995temporal,
  title={Temporal difference learning and TD-Gammon},
  author={Tesauro, Gerald},
  journal={Communications of the ACM},
  volume={38},
  number={3},
  pages={58--68},
  year={1995}
}

@article{mnih2013playing,
  title={Playing Atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{hornik1991approximation,
  title={Approximation capabilities of multilayer feedforward networks},
  author={Hornik, Kurt},
  journal={Neural networks},
  volume={4},
  number={2},
  pages={251--257},
  year={1991},
  publisher={Elsevier}
}

@article{srivastava2014dropout,
  title={Dropout: A simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@inproceedings{sarle1995stopped,
  title={Stopped training and other remedies for overfitting},
  author={Sarle, Warren S},
  booktitle={Proceedings of the 27th Symposium on the Interface of Computing Science and Statisfi (.'. \_$\backslash$‘. pp. 352-360. Interface Foundation of North America, Fairfax Station. VA, USA},
  year={1995}
}

@phdthesis{Werbos74,
    address = {Cambridge, MA},
    author = {Werbos, P.},
    school = {Harvard University},
    title = {Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences},
    year = {1974}
}

@incollection{Rumelhart1988,
 author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
 chapter = {Learning Representations by Back-propagating Errors},
 title = {Neurocomputing: Foundations of Research},
 editor = {Anderson, James A. and Rosenfeld, Edward},
 year = {1988},
 isbn = {0-262-01097-6},
 pages = {696--699},
 numpages = {4},
 url = {http://dl.acm.org/citation.cfm?id=65669.104451},
 acmid = {104451},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}

@inproceedings{bergstra2011algorithms,
  title={Algorithms for hyper-parameter optimization},
  author={Bergstra, James S and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2546--2554},
  year={2011}
}

@inproceedings{bhatnagar2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S and Maei, Hamid R and Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1204--1212},
  year={2009}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation.},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  journal={Advances in Neural Information Processing Systems},
  volume={12},
  pages={1057--1063},
  year={2000},
  publisher={MIT press}
}

@article{halton1970retrospective,
  title={A retrospective and prospective survey of the Monte Carlo method},
  author={Halton, John H},
  journal={Siam review},
  volume={12},
  number={1},
  pages={1--63},
  year={1970},
  publisher={SIAM}
}

@inproceedings{Hasselt2009,
  title={Using continuous action spaces to solve discrete problems},
  author={van Hasselt, Hado and Wiering, Marco A},
  booktitle={Neural Networks, 2009. IJCNN 2009. International Joint Conference on},
  pages={1149--1156},
  year={2009},
  organization={IEEE}
}

@article{Levine2013,
  title={Exploring Deep and Recurrent Architectures for Optimal Control},
  url={http://arxiv.org/abs/1311.1761},
  journal={arXiv preprint arXiv:1311.1761},
  author={Levine, Sergey},
  year={2013},
  pages={1--8}
}