\documentclass{ludis} % pieejams https://github.com/rihardsk/LU-nosl-guma-darbs---LaTeX

% xelatex
\usepackage{fontspec}
\usepackage{xunicode}
\usepackage{xltxtra}

%\usepackage[utf8]{inputenc}

\usepackage[]{hyperref}
\hypersetup{
    colorlinks=false
}
\urlstyle{same}

% languages
\usepackage{fixlatvian}
\usepackage{polyglossia}
\setdefaultlanguage{latvian}
\setotherlanguages{english,russian}

% fonts
\usepackage{xltxtra}
% \setmainfont[Mapping=tex-text]{Times New Roman}
%\defaultfontfeatures{Scale=MatchLowercase,Mapping=tex-text}

% bibliography
%\usepackage{csquotes}
\usepackage[
    backend=biber,
    style=numeric-comp,
    sorting=none,
    natbib=true,
    url=false,
    doi=true%,
    %eprint=false
]{biblatex}
\addbibresource{bibliography.bib}

% toc
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

%tables
\usepackage{longtable}

%papildus matemātika
\usepackage[showonlyrefs]{mathtools}
\newenvironment{thmenum}
 {\begin{enumerate}[label=\upshape(\arabic*),ref=\thethm(\arabic*)]}
 {\end{enumerate}}
\usepackage{amsmath}

%pseidokodam
%\usepackage[noend]{algpseudocode}
%\usepackage{algpseudocode}
\usepackage[boxed,linesnumbered]{algorithm2e}
\SetAlgorithmName{Algoritms}{}{Algoritmu saraksts}

%main line spacing, kur vajag
\usepackage{setspace}

%lai flushotu floatus
\usepackage{placeins}

%images
\usepackage{graphicx}
\usepackage{float}
\usepackage{svg}

%dalīšana kolonnās
\usepackage{multicol}

%saraksti
\usepackage{enumitem}

\fakultate{Datorikas}
\nosaukums{Paredzošā stimulētā mācišanās}
\darbaveids{Maģistra kursa}
\autors{Rihards Krišlauks}
\studapl{rk09006}
\vaditajs{Asoc.prof., Dr. dat. Jānis Zuters}
%\recenzents{Juris Vīksna profesors Dr.sc.comp.}
\vieta{Rīga}
\gads{2015}

\begin{document}
\maketitle

\begin{abstract-lv}
  TODO

\keywords{stimulētā mācīšanās; neironu tīkli; Markova izvēles procesi; nepārtrauktas telpas.}
\end{abstract-lv}
\clearpage

\begin{abstract-en}
  TODO

\keywords{reinforcement learning; artificial neural networks; Markov decision processes; continuous spaces.}
\end{abstract-en}


\tableofcontents

\iffalse
\specnodala{Apzīmējumu saraksts}
\setlength\LTleft{0pt}
\setlength\LTright{0pt}
\begin{longtable}{| c | p{28em} |}
  \hline
  \textbf{Apzīmējums} & \textbf{Atšifrējums}\\ 
  \endhead

  \hline
  $D_X \in \mathbb{N}_+$ & \\ %TODO šis jādefinē arī telpas elementiem
  $S \subseteq \mathbb{R}^{D_S}$ & \\
  $A \subseteq \mathbb{R}^{D_A}$ & \\
  $R:S \times A \times S \rightarrow \mathbb{R}$ & \\
  $T:S \times A \times S \rightarrow [0,1]$ & Apzīmējuma nosaukums \\
  $\pi(s, a)$ &  Apzīmējuma nosaukums 2\\
  \hline
\end{longtable}
\fi

\specnodala{Ievads}
Pēdējā laikā teorētiskajā neirozinātnē plašu piekrišanu sāk iegūt t.s.
paredzošās kodēšanas (predictive coding) teorija, kuras pamattēze ir --
smadzenes ir paredzēšanas mašīnas, tās pastāvīgi cenšas sapārot ienākošos
sensoru signālus ar augsta līmeņa paredzējumiem ar mērķi minimizēt paredzēšanas
kļūdas. Paredzošā kodēšana sniedz vienotu skatījumu uz procesiem, kas ir pamatā
cilvēka apziņai, un piedāvā mehānismu, kas ļauj izskaidrot plašu klāstu ar
neirozinātnē pētītiem cilvēka apziņas fenomeniem \autocite{Clark2013}.

Ideja par smadzenēm kā māšīnām, kas, ņemot vērā pašreizējos novērojumus, cenšas
paredzēt nākotnes novērojumus, ir ļoti pievilcīga no dažādu mašīnmācīšanās
paradigmu skatpunkta. Šis vienkāršais mehānisms šķiet viegli formulējams kā
mašīnmācīšanās problēma, un šķiet it īpaši piemērots, lai to izteiktu kā
stimulētās mācīšanās problēmu.

Stimulētā mācīšanās ir mašīnmācīšanās paradigma, kas formalizē mācīšanos kā
mašīnmācīšanās uzdevumu. Tās pamatā ir ideja par vidi un aģentu, kas tajā
darbojas. Aģenta mērķis ir, ņemot vērā ārēju atalgojuma signālu, veikt darbības
vidē tā, lai maksimizētu saņemto atalgojumu. Šis vienkāršais, bet spēcīgais,
uzstādījums ļauj aprakstīt un risināt ļoti plašu problēmu loku, kur optimālā
rīcības stratēģija nav zināma, bet ir iespējams nodefinēt stāvokli, ko aģentam
būtu jācešas sasniegt. Aģenta ziņā paliek, darbojoties vidē, laika gaitā atrast
optimālo stratēģiju, kas ļautu sasniegt pēc iespējas lielāku atalgojumu. Kā
piemērus šādi risināmām problēmām var minēt orientēšanos labirintā vai
automātisku lidaparāta kontroli.

No augstāk minētā dabīgi seko doma par paredzošās kodēšanas ideju pielietošanu
stimulētās mācīšanās uzdevumu risināšanā. Interesi raisa ideja par vides nākamā
stāvokļa paredzēšanu, ņēmot vērā pašreizējo, un vai tas palīdzētu mācīšanās
procesā. Tas liktu stimulētās mācīšanās aģentam tuvināti iemācīties vides
modeli. Tuvākas izpētes vērts ir jautājums, vai šāds iekšējs modelis palīdzētu
macīšanās procesā.

Šajā darbā tiks pētītas iespējas, izmantot paredzošās kodēšanas idejas stimulētās
mācīšanas uzdevumu risināšanai, kā arī tiek pētītas dažādas citas iespējas ar
papildus informāciju uzlabot mācīšanās ātrumu. Darbs tiek iesākts ar vispārīgu stimulētās
mācīšanās paradigmas apskatu, kur autors galvenokārt pieturas pie izklāsta kas
atrodams \autocite{Krislauks2015}. Tam seko COMBO CACLA algoritma apraksts, un
salīdzinājums ar CACLA algoritmu, uz kā tas ir balstīts. %TODO papildināt, kad
                                %ir vairāk gatavs no satura
%NOTE: pie cacla algoritma jāpastāsta, kas ir tie aspekti, kas padara viņu
%pievilcīgu modifikācijām.
\chapter{CCACLA algoritms}\label{chap:ccacla}
CACLA algoritms izmanto divus neironu tīklus, no kuriem viens aproksimē optimālo
stratēģiju, bet otrs -- stāvokļu vērtības funkciju. Abu neironu tīklu parametri
tiek pielāgoti, tiem savstarpēji mijiedarbojoties algoritma darbības laikā --
stāvokļu vērtības funkcija ir atkarīga no optimālās stratēģijas aproksimācijas,
jo tā nosaka, kādas darbības tiek veiktas katrā stāvoklī, kas laika gaitā
ietekmē stāvokļu vērtību, savukārt optimālās stratēģijas aproksimācija tiek
pielāgota atkarībā no stāvokļu funkcijas izmaiņām, ņemot vērā, vai stratēģijas
noteiktā darbība dotā stāvoklī pēc izpildes palielina stāvokļa vērtību. Šīs
savstarpējās mijiedarbības rezultātā algritms ir spējīgs mācīties, bet rodas
jautājums, vai šādi netiek darīts lieks darbs. Gan stāvokļu vērtības funkcijas
aproksimācijas $V$ gan optimālās stratēģijas funkcijas aproksimācijas $A$ domēns
ir vides stāvokļu telpa $S$. Ir saprātīgi pieņemt, ka abu funkciju vērtības
varētu noteikt līdzīgas pazīmes stāvokļu telpā. Abu attiecīgo neironu tīklu
otrais slānis varētu būt trenēšānas rezultātā iemācījies izejā dot līdzīgus
aktivācijas vienos un tajos pašos stāvokļus, tāpēc rodas jautājums, vai abus
tīklus nav iespējams apvienot.

Skatījumu uz neironu tīkliem kā hierarhiskiem pazīmju izgūšanas rīkiem sniedz
pēdējā laikā lielu popularitāti ieguvusī dziļās mācīšanās paradigma. Tās pamatā
ir ideja, ka daudzos dažādos ar reālo pasauli saistītos domēnos, piemēram, attēlu
vai runas atpazīšānā, dabīgās valodas apstrādē u.c., pētāmos objektus ir
iespējams raksturot ar hierarhisku vairāklīmeņu pazīmju kopumu \autocite{Lecun2015}. Tas ļauj
izmantot vairākļīmeņu neironu tīklus šo pazīmju izgūšanai. %TODO piemērs
Lai arī šajā darbā apskatītajās stimulētās mačīšanās problēmas atāvokļu telpas
nav tik sarežģītas, lai būtu nepieciešamība izmanot dziļus neironu tīklus, tomēr
arī uz sekliem neironu tīkliem var raudzīties kā uz ierīcēm, kas izgūst zema
līmeņa pazīmes, ko pēdējais tīkla līmenis ir iemācījies apstrādāt. Šis skatījums
rada papildus motivāciju pētīt, vai nav iespējams lietderīgi izmantot CACLA
algoritmā izmantoto neironu tīklu apakšējo līmeņu izgūto pazīmju īpatnības.

Šajā nodaļā tiks apskatītas vairākas CACLA algoritma modifikācijas, kuras to
kopīgo īpašību dēļ autors ievieto vienā algoritmu grupā ar kopīgo nosaukumu
Combined CACLA, jeb CCACLA. Visu algoritmu kopīgā iezīme, kas tos atšķir no
iepriekš apskatītā CACLA algoritma ir viena neironu tīkla izmantošana gan
vērtību funkcijas $V$ gan optimālās stratēģijas funkcijas $A$ aproksimācijai.
Tiek apskatīti vairāki šī algoritma paveidi, kas ietver modifikācijas tajā, kāda
informācija tiek izmantota tīkla trenēšanai.

%TODO jāpasaka kaut kas par to, ka tiek šeit CACLA un CCACLA algoritmi tiek
%aprakstīti tikai kontekstā ar neironu tīkliem. Idejas par kopīgu slāņu
%izmantošanu gan aktiera gan kritiķa komponentei dabīgāk sasaistāmas ar neironu
%tīkliem kā šo komponenšu implementācijām. Pastāv tomēr arī iespējas
%alternatīvam formulējumam, kas izmanto patvaļīgus funkciju aproksimatorus. Šajā
%interpretācijā uzdevums pārvēršas par mēģinājumu atrast kādu parametru
%komplektu, ko šie funkciju aproksimētāji varētu dalīt savā starpā.
\section{CCACLA pamatalgoritms}
CCACLA vienkāršākais variants, kas vismazāk atšķiras no par pamatu ņemtā CACLA
algoritma, izmanto funkciju 
\begin{equation}
  Av_\Theta:S \rightarrow A \times \mathbb{R},
\end{equation}
lai stāvoklī $s$ paredzētu gan optimālo darbību $a$, gan stāvokļa vērtību $v$ kā
$Av_\Theta(s) = (a, v)$. Funkcija $Av_\Theta$ tiek realizēta ar
neironu tīklu, kas sastāv no ieejas slāņa, slēptā slāņa, un diviem izejas
slāņiem, kas slēptā slāņa aktivācijas pārvērš, respektīvi, optimālajā darbībā
$a$ un stāvokļa vērtībā. Šīs vērtības tad attiecīgi var izteikt, kā
\begin{equation}\label{eq:ccacla-act}
  v = V(s), V(s) = f_a\left(f_h(s^T \cdot W_h) \cdot W_a\right)
\end{equation} un
\begin{equation}\label{eq:ccacla-val}
  a = Ac(s), Ac(s) = f_v\left(f_h(s^T \cdot W_h) \cdot W_v\right)
\end{equation}, kur $s$ ir
ieejas vektors (stāvoklis), $W_h$ ir slēptā slāņa svaru matrica, $W_a$ ir
darbības slāņā svaru matrica, $W_v$ ir vērtības slāņa svaru matrica, $f_h$ ir
slēptā slāņā aktivācijas funkcija, $f_a$ ir darbības slāņā aktivācijas funkcija
un $f_v$ ir vērtības slāņā aktivācijas funkcija. Ar ieviestajiem mainīgajiem
varam arī izteikt funkciju $Av$
\begin{equation}\label{eq:ccacla-actval}
  Av(s) = \left(f_a(h^{(1 \ldots D(A))}), f_v(h^{(D(A) + 1)})\right), \text{ kur } 
  h = f_h\left(f_h(s^T \cdot W_h) \cdot W_v\right)
\end{equation}
%TODO: pateikt, ka bias vērtības ir iekļautas W

Citos aspektos CCACLA pamatalgoritms neatšķiras no CACLA. Šādi izteiktas funkcijas
$V(s)$ un $Ac(s)$ ļauj izmantot jau iepriekš definēto CACLA algoritmu <reference
uz cacla pseidokodu>. Atbilstoši vienādojumam \ref{eq:ccacla-actval} iespējams
arī definēt optimizētu versiju, kas izmanto faktu, ka $a$ un $v$ iespējams
izrēķināt vienlaicīgi. Tas parādīts algoritmā \ref{alg:ccacla-basic}.

\begin{spacing}{1}
\begin{algorithm}
\caption{CACLA pseidokods}\label{alg:ccacla-basic}
inicializē $\theta_0, \psi_0, s_0$ \\
$(a_0', v_0) := Av_0(s_0)$ \\
ņem $a_0$ ar izkliedi ap $a_0'$ \\
\For{$t \in \{1,2,\ldots\}$}{
	veic $a_{t-1}$, novēro $r_{t-1}, s_t$ \\
  $(a_t', v_t) := Av_t(s_t)$ \\
	ņem $a_t$ ar izkliedi ap $a_t'$ \\
	\eIf{$s_t$ ir gala stāvoklis}{
		$V_t(s_{t-1}) \xleftarrow{\alpha_{t-1}(s_{t-1})} r_{t-1}$ \\
		ņem jaunu $s_t$ ($s_t$ ir sākumstāvoklis nākamajā trenēšanas epizodē)
    % TODO: šeit jāiestata arī a un v (vai arī jāpievieno ārējais cikls, un šeit
    % var rakstīt goto 1)
	}{
		$V_t(s_{t-1}) \xleftarrow{\alpha_t(s_{t-1})} r_{t-1} + \gamma v_t$
	}
	\If{$r_{t-1} + \gamma v_t > v_{t-1}$}{
		$V_t(s_{t-1}) \xleftarrow{\beta_t(s_{t-1})} a_{t-1}$
	}
}
\end{algorithm}
\end{spacing}

% Algoritma \ref{alg:ccacla-basic} 9. un 14. rindiņā nepieciešams veikt gradient
% descent soļus funkcijām \ref{eq:ccacla-act} un \ref{eq:ccacla-val}, kam
% nepieciešami šo funkciju diferenciāļi.
% \begin{equation}
%   \frac{\partial V}{\partial s} = 
% \end{equation}
%TODO varbūt jāpastāsta par bakcprop. skat: https://en.wikipedia.org/wiki/Backpropagation

\section{CCACLA ar stāvokļa paredzēšanu}
Kā tika minēts iepriekš, interesi rada jautājums, vai ir iespējams ar kādas
papildinformācijas palīdzību trenēšanas laikā likt stimulētās mācīšanās aģentam
veidot iekšēju vides modeli ar mērķi paātrināt mācīšanos. Šajā nolūkā tiek
ieviests CCACLA algoritms ar stāvokļa paredzēšanu, kas no iepriekš aprakstītā
CCACLA pamatalgoritma atšķiras ar to, ka kombinētajam neironu tīklam tagad ir
jāparedz arī nākamais stāvoklis, kurā nonāks aģents pēc paredzētās optimālās
darbības veikšanas. Tas noved pie funkcijas $Aov$ 
\begin{equation}
  Aov_\Theta:S \rightarrow A \times S \times \mathbb{R}
\end{equation}
Līdz ar funkciju \ref{eq:ccacla-act} un \ref{eq:ccacla-val} tagad ieviesīsim arī
funkciju $St$, kas vēlāk tiks izmantota, CCACLA' algiritma pseidokodā, lai
atvieglotu gradient descent soļu pierakstu
\begin{equation}\label{eq:ccacla-obs}
  s' = St(s), St(s) = f_s(f_h(s^T \cdot W_h) \cdot W_a)
\end{equation} 
, kur $W_S$ ir nākamā stāvokļa paredzēšanas slāņa svaru matrica, un $f_S$ ir
slāņa aktivācijas funkcija.
Analogi vienādojumam \ref{eq:ccacla-actval} tagad varam definēt funkciju $Aov$,
kas parāda, kā funkciju \ref{eq:ccacla-act}, \ref{eq:ccacla-act} un
\ref{eq:ccacla-act} apvieno vienā neironu tīklā.
\begin{multline}\label{eq:ccacla-actobsval}
  Aov(s) = \left(f_a(h^{(1 \ldots D(A))}),
                 f_s(h^{(D(A) + 1 \ldots D(A) + D(S))}),
                 f_v(h^{(D(A) + D(S) + 1)})\right), \\
  \text{ kur } h = f_h\left(f_h(s^T \cdot W_h) \cdot W_v\right)
\end{multline}

Lai aprakstītu CACLA' pseidokodā pietrūkst vēl viena funkcija. Atšķirība no
CCACLA pamatalgoritma ir tajā, ka tagad nākas šķirot gadījumus, kuros
trenēšanai kā ieejas dati ir pieejama stāvokļa vārtība, kuros -- nākamais
stāvoklis, kuros -- optimālā darbība, un kuros ir pieejama kāda kombinācija no
minētajām vērtībām. Tādēļ nākas ieviest funkciju, nākamā stāvokļa paredzēšānai
un esošā stāvokļa vērtības paredzēšanai.
\begin{multline}\label{eq:ccacla-obsval}
  Ov: S \rightarrow S \times \mathbb{R},
        Ov(s) = \left(f_s(h^{(D(A) + 1 \ldots D(A) + D(S))}),
                 f_v(h^{(D(A) + D(S) + 1)})\right), \\
  \text{ kur } h = f_h\left(f_h(s^T \cdot W_h) \cdot W_v\right)
\end{multline}
Ar tās un iepriekš definēto funkciju paldīzību varam ideju definēt precīzāk
algoritmā \ref{alg:ccacla-state}.

\begin{spacing}{1}
\begin{algorithm}
\caption{CACLA pseidokods}\label{alg:ccacla-state}
inicializē $\theta_0, \psi_0, s_0$ \\
$(a_0', v_0) := Av_0(s_0)$ \\
ņem $a_0$ ar izkliedi ap $a_0'$ \\
\For{$t \in \{1,2,\ldots\}$}{
	veic $a_{t-1}$, novēro $r_{t-1}, s_t$ \\
  $(a_t', v_t) := Av_t(s_t)$ \\
	ņem $a_t$ ar izkliedi ap $a_t'$ \\
	\eIf{$s_t$ ir gala stāvoklis}{
    \eIf{$r_{t-1} + \gamma v_t > v_{t-1}$}{
      $Av_t(s_{t-1}) \xleftarrow{\alpha_{t-1}(s_{t-1})} (a_{t-1}, r_{t-1})$ \\
    }{
      $V_t(s_{t-1}) \xleftarrow{\alpha_{t-1}(s_{t-1})} r_{t-1}$ \\
    }
		ņem jaunu $s_t$ ($s_t$ ir sākumstāvoklis nākamajā trenēšan as epizodē)
    % TODO: šeit jāiestata arī a un v (vai arī jāpievieno ārējais cikls, un šeit
    % var rakstīt goto 1)
	}{
    \eIf{$r_{t-1} + \gamma v_t > v_{t-1}$}{
      $Aov_t(s_{t-1}) \xleftarrow{\alpha_t(s_{t-1})} (a_{t-1}, s_t, r_{t-1} + \gamma v_t)$
    }{
      $Ov_t(s_{t-1}) \xleftarrow{\alpha_t(s_{t-1})} (s_t, r_{t-1} + \gamma v_t)$
    }
	}
}
\end{algorithm}
\end{spacing}

\section{CCACLA ar paredzēšanu nākotnē}
Iepriekšējā sadaļā aprakstītais CCACLA algoritms ar stāvokļa paredzēšānu ir
veidots ar mērķi trenēšanas laikā likt stimulētās mācīšanās aģentam veidot
iekšēju vides modeli. Algoritma formulējumā gan var ievērot kādu īpatnību.
Funkcija $Aov(s) = (a, s', v)$ dotam stāvoklim $s$ atgriež optimālo darbību $a$
un stāvokli $s'$, kurā vide (visticamāk) nonāks pēc $a$ veikšanas, tomēr
atgrieztā vērtība $v$ atbilst stāvoklim $s$, nevis $s'$. Vērtības $v$
sasaistīšana ar $s$ atbilst oriģinālajam CACLA algoritma formulējumam, tomēr
varētu uzdot jautājumu, vai, liekot algoritma neironu tīklam paredzēt gan nākamo
stāvokli gan šī stāvokļa vērtību, nevar uzlabot algoritma darbību. Sasaistot šo
ideju ar iepriekš izteikto mērķi mēģināt rast veidus, kā stimulētās mācīšanās
aģentam likt veidot iekšēju vides modeli, ideju var intuitīvi pamatot, sakot, ka
nākamā stāvokļa vērtības paredzēšanai šāds modelis ir nepieciešams.

Ņemot vērā iepriekšējos apsvērumus, veidosim algoritma CCACLA variantu ar
paredzēšanu nākotnē. Šis algoritma variants izmantos tādu pat neirona tīkla
struktūru, kā CCACLA ar stāvokļa paredzēšanu. Atšķirības būs tikai tīkla
trenēšanas procesā, kā rezultātā tiks pielāgoti funkciju $V$, $Ov$ un $Aov$
parametri tā, lai stāvokļa vērtība, ko atgriež šīs funkcijas, atbilstu stāvoklim
$s'$ nevis $s$. Viennozīmības labad CCACLA algoritmā ar paredzēšanu nākotnē
apzīmēsim šīs funkcijas, attiecīgi kā $V'$, $Ov'$ un $Aov'$. Šīs funkcijas
nemainīgi tiek definētas atbilstoši
vienādojumiem~\eqref{eq:ccacla-val}~\eqref{eq:ccacla-obsval}~\eqref{eq:ccacla-actobsval}.
CCACLA ar paredzēšanu nākotnē precīzāk definēts algoritmā \ref{alg:ccacla-state}


\begin{spacing}{1}
\begin{algorithm}
\caption{CACLA ar parezēšānu nākotnē pseidokods}\label{alg:ccacla-future}
inicializē $\theta_0, \psi_0, s_0$ \\
$(a_0', v_1) := Av_0(s_0)$ \\
ņem $a_0$ ar izkliedi ap $a_0'$ \\
\For{$t \in \{1,2,\ldots\}$}{
	veic $a_{t-1}$, novēro $r_{t-1}, s_t$ \\
  $(a_t', v_{t+1}) := Av_t(s_t)$ \\
	ņem $a_t$ ar izkliedi ap $a_t'$ \\
  \If{$s_{t-1}$ vai $s_t$ ir sākumstāvoklis}{
    continue
  }
	\eIf{$s_t$ ir gala stāvoklis}{
    \eIf{$r_{t-1} + \gamma v_t > v_{t-1}$}{
      $Av_t(s_{t-2}) \xleftarrow{\alpha_{t-1}(s_{t-2})} (a_{t-1}, r_{t-1})$ \\
    }{
      $V_t(s_{t-2}) \xleftarrow{\alpha_{t-1}(s_{t-2})} r_{t-1}$ \\
    }
		ņem jaunu $s_t$ ($s_t$ ir sākumstāvoklis nākamajā trenēšan as epizodē)
    % TODO: šeit jāiestata arī a un v (vai arī jāpievieno ārējais cikls, un šeit
    % var rakstīt goto 1)
	}{
    \eIf{$r_{t-1} + \gamma v_t > v_{t-1}$}{
      $Aov_t(s_{t-2}) \xleftarrow{\alpha_t(s_{t-2})} (a_{t-1}, s_t, r_{t-1} + \gamma v_t)$
    }{
      $Ov_t(s_{t-2}) \xleftarrow{\alpha_t(s_{t-2})} (s_t, r_{t-1} + \gamma v_t)$
    }
	}
}
\end{algorithm}
\end{spacing}

\chapter{Stimulētās mācīšanās vides}
Nodaļā tiks sniegts īss ieskats tālāk aprakstītajos eksperimentos~\ref{chap:exp}
izmantoto stimulētās mācīšanās vižu īpatnībās. Tiks apskatītas 4 dažādas
stimulētās mācīšanās vides -- cart-pole, mountain car, acrobat, helicopter.
Visiem uzdevumiem ir nepērtrauktas stāvokļu telpas, tomēr to stāvokļu telpu
dimensiju skaits, kā arī darbību telpu veids un dimensiju skaits atšķiras.

\section{Cart-pole vide}
Cart-pole vidē ir jāveic kārts balansēšanas uzdevums \autocite{Barto}. Mērķis ir
pēc iespējas ilgāk balansēt kārti, kas piestiprināta kustīgā eņģē pie
horizontāli (vienā dimensijā) kustināmiem ratiņiem. Aģents mijiedarbojas ar vidi
pielietojot spēku ratiņiem vienā vai otrā virzienā. Katrā laika vienībā, kurā
kārts nav apgāzusies, t.i., tā atrodas kādā noteiktā leņķu intervālā attiecībā
pret zemi, un kurā ratiņi nav izbraukuši ārpus norādītām robežām, aģents saņem
atalgojumu 1. Ja kāds no šiem kritērijiem neizpildās, aģents saņem atalgojumu 0,
un tiek sākta jauna uzdevuma epizode.

Uzdevumam ir 4 dimensiju nepārtraukta stāvokļu telpa. Vides stāvokli raksturo
vektors $(x, v, \theta, \omega) \in \mathbb{R}^4$, kur $x$ ir ratiņu pozīcija,
$v$ ir ratiņu horizontālais ātrums, $\theta$ ir kārts leņķis un $\omega$ ir
kārts leņķiskais ātrums. Vides dinamiku apraksta vienādojumi
\begin{gather}
  \ddot{\theta} = \frac{g \sin\theta_t + \cos\theta_t \left(\frac{-F - m_p l \omega_t^2\sin\theta_t}
                                                         {m_c + m_p}\right)}
                        {l \left(\frac{4}{3} - \frac{m_p\cos^2\theta_t}
                                               {m_c + m_p}\right)} \\ 
  \ddot{x} = \frac{F + m_p l \left(\omega_t^2\sin\theta_t - \ddot{\theta}\cos\theta_t\right)}
                   {m_c + m_p} \\
  x_{t+1} = x_t + v_t \\
  v_{t+1} = v_t + \ddot{x} \\
  \theta_{t+1} = \theta_t + \omega_t \\
  \omega_{t+1} = \omega_t + \ddot{\theta}
\end{gather},
kur $l$ ir kārts garums, $m_p$ ir kārts masa, $m_c$ ir ratiņu masa un $F$ ir
aģenta pielietotais spēks ir aģenta pielietotais spēks. Šajos vienādojumos
netiek ņemta vērā berze starp ratiņiem un virsmu, uz kuras tie kustās.

Uzdevumam ir 1 dimensijas nepārtraukta darbību telpa. Katrā laika vienībā
aģentam ir iespēja noteikt spēku $F \in \mathbb{R}$, ar kuru tas iedarbosies uz
ratiņiem.

\section{Mountain car vide}
Mountain car uzdevumā aģentam ir jāuzbrauc no parabolas tipe ieplakas (divās
dimensijās) ar mašīnu, kam pietrūkst jaudas, lai to izdarītu bez ieskrējiena.
Lai pārvarētu uzdevumu, aģentam nākas vairākas reizes pārvietoties augšā
pamīšus pretējās ieplakas malās, lai iegūtu potenciālo enerģiju, kas ļautu no
ieplakas izbraukt. Uzdeums ir interesants ar to, ka 

\section{Acrobat vide}

\section{Helicopter vide}



\chapter{Veiktie eksperimenti un rezultāti}\label{chap:exp}
Darba gaitā tika veikti vairāki eksperimenti ar mērķi novērtēt
nodaļā~\ref{chap:ccacla} aprakstīto algoritmu veiktspēju, un tos savstarpēji
salīdzināt. Lai arī darba gaitā tikai pastāvīgi veikti dažādi stimulētās
mācīšanās eksperimenti, kas palīdzēja virzīt aprakstīto algoritmu izstrādi, šajā
nodaļā ir aprakstīta tikai daļa no tiem, kas parāda izstrādāto algoritmu
savstarpējo salīdzinājumu.

\section{Eksperimentu tehniskā realizācija}
Stimulētās mācīšanās eksperimentu vadīšānai tikai izmantots RL-Glue
programmēšanas ietvars \autocite{rl-glue}. RL-Glue ietvars sniedz iespēju veidot
modulārus stimulētās mācīšanās eksperimentus, kur uzdevuma vide, aģents un
eksperiments ir atsevišķas komponentes, starp kurām komunikāciju vada RL-Glue
programmatūra. Komponentes ir valodneatkarīgas. Tas nodrošināja iespēju izmantot
publiski pieejamas, iepriekš implementētas stimulētās mācīšanās vides izstrādāto
aģentu pārbaudīšanai. 

Eksperimentos tika izmantotas vides, kas piejamas RL-Library interneta vietnē
\autocite{rl-library}. Tās ir programmētas valodā Java, un realizē diskrētas vai
nepārtrauktas stāvokļu telpas un diskrētas darbību telpas. Tā kā šī darba
ietvaros īpaši tiek apskatīti algoritmi, kas paredzēti nepārtrauktām darbību
telpām, tad vienai no vidēm -- Cart Pole -- tika veiktas izmaiņas, lai tā
pieņemtu skalārus lielumus kā darbības.

Stimulētās mācišanās aģenti, kas realizē nodaļā~\ref{chap:ccacla} aprakstītos
algoritmus, tika rakstīti valodā Python. Algoritmos izmantotie neironu tīkli
tika programmēti ar Theano bibliotēkas palīdzību \autocite{Bastien-Theano-2012}
\autocite{bergstra+al:2010-scipy}, kas kompilē un optimizē simboliskas
matemātiskas izteiksmes darbināšānai uz datora procesora vai videokartes, kā arī
ļauj veikt automātisku funkciju atvasināšanu, kas ievērojami atvieglo neironu
tīklu trenēšanu, un ļauj viegli veidot sarežģītas arhitektūras neironu tīklus.
Tas būtiski atvieglo CCACLA algoritma variantos izmantotās kombinētās neironu
tīkla arhitektūras izveidi. Papildus tika izmantota Lasagne bibliotēka, kas ir
balstīta uz Theano, un piedāvā atkalizmantojamas komponentes neironu tīklu slāņu
definēšanai \autocite{lasagne}.

Lai nodrošinātu iespēju veidot atkārtojamu eksperimentu specifikācijas, kā arī
darbināt eksperimentus paralēli un uz vairākiem tīklā saslēgtiem datoriem, tika
izmantota ipyparallel bibliotēka \autocite{ipyparallel} un pašizveidots
kofigurācijas failu pieraksts paralēlu RL-Glue eksperimentu specificēšanai, kā
arī attiecīgā programmatūra eksperimentu darbināšanai.
%TODO: linki uz abiem repozitorijiem

\section{Vides specifikācija}
Veicot eksperimentus, vidēm tika lietotas to noklusējuma konfigurācijas.
Cart-pole uzdevumā atļautais intervāls kārts leņķim $\theta$ bija $(-12; 12)$
grādi, un atļautais intervāls ratiņu pozīcijai $x$ bija $(-2,4; 2,4)$.
%TODO: par citām vidēm


\section{Modeļu specifikācija}
CACLA algoritmā tika izmantoti divi neironu tīkli, kur katram bija 20
neironi slēptajā slānī. CCACLA, CCACLA ar stāvokļa paredzēšanu un CCACLA ar
paredzēšanu nākotnē algoritmos katrā tika izmantots viens neironu tīkls ar 20
neironiem slēptajā slānī. Ieejas un izejas slāņu neironu skaits bija atkarīgs no
konkrētā uzdevuma stāvokļu un darbību telpām. Visiem neironu tīkliem slēptajā
slānī tika izmantota \textit{rectify} aktivācijas funckija un identitātes
aktivācijas funkcija izejas slānī. Aģentu trenēšanas procesā tika izmantots
aditīvs troksnis ar sadalījumu $\mathcal{N}(0, 0,05)$, kas tika pievienots
izvēlētajām darbībām, lai veicinātu stāvokļu telpas izpēti.

Sākotnēji izstrādājot algoritmus, tika eksperimentēts ar dažādiem citiem
hiperparametriem. Tika izmēģināti neironu tīkli ar lielāku slēpto stāvokļu
skaitu, tika izmēģināta $l1$ un $l2$ regularizācija, tika mēģināts izmantot
\textit{gradient clipping}, lai cīnītos ar treniņu diverģēšanu pie pārāk
augstiem mācīšanās tempa uzstādījumiem. Neviena no šīm izmaiņām tomēr netiek
atspoguļota gala rezultātos, jo to mērķis ir parādīt algoritmu savstarpējo
salīdzinājumu, pie vienādas un pēc iespējas vienkāršākas hiperparametru izvēles.
Turlkāt netika novērots, ka kāda no minētajām izmaiņām sniegtu būtisku ieguvumu
aģentu trenēšanas procesā.


\section{Eksperimentu metodika}
Salīdzināšana tika veikta, novērtējot algoritmus CACLA, CCACLA, CCACLA ar
stāvokļa paredzēšanu un CCACLA ar paredzēšanu nākotnē. Katrs no ar attiecīgo
algoritmu trenētajiem aģentiem tika pārbaudīts cart-pole uzdevumā. Katram no
algoritmiem tika veikti 10 eksperimenti. Katrs eksperiments ilga 50000 epizodes
(visi apskatītie stimulētās mācīšanās uzdevumi ir epizodiski). Atsevišķie
eksperimenti tika apkopoti, lai iegūtu attiecīgā algoritma vidējo rezultātu.
Eksperimentu gaitā tika apkopota kopējā katrā epizodē iegūtā atalgojuma vērtība,
kā arī tika veidota statistika par vidējo līdz epizodei iegūto atalgojuma
vērtību ar mērķi skaidrāk attēlot kopējo algoritma sniegumu, neņemot vērā
troksni trenēšanas procesā.

Trenēšanas procesā tika novērots, ka atsevišķos gadījumos aģenti mēdza iestrēgt
pārmēru sliktās stratēģijās. Tas bija novērojams kā liels kritums aģenta iegūto
atalgojumu līknē treniņa procesa vidū, kas turpinās līdz pat treniņa procesa
beigām. Šādi gadījumi tika uzskatīti par anomālijām, un netika iekļauti gala
rezultātos, jo atstāja dramatisku iespaidu uz aģenta iegūto vidējo atalgojumu 10
veiktajos eksperimentos. Šī iemesla dēļ atsevišķos grafikos ir attēloti mazāk
par 10 eksperimentiem kādam konkrētam aģentam. Tipiski šādu anomāliju skaits
netika novērots vairāk kā 2 no 10 eksperimentos.


\section{Rezultāti}
Apskatot cart-pole uzdevumu
\begin{figure}
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Img/{pma.all.normal}.pdf}
  \caption{CACLA iegūtais atalgojums}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Img/{pfa.all.normal}.pdf}
  \caption{CCACLA ar paredzēšanu nākotnē iegūtais atalgojums}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Img/{both.mean.normal}.pdf}
  \caption{Visu algoritmu vidējie rezultāti}
\end{figure}

 
\chapter{Diskusija}
TODO
\chapter{Secinājumi}
TODO


\printbibliography
\end{document}

%%% Local Variables:
%%% coding: utf-8
%%% mode: latex
%%% TeX-master: t
%%% TeX-engine: xetex
%%% reftex-default-bibliography: ("bibliography.bib")
%%% End:

%%% TeX-command-extra-options: "-shell-escape"