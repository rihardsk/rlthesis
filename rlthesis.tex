\documentclass{ludis} % pieejams https://github.com/rihardsk/LU-nosl-guma-darbs---LaTeX

% xelatex
\usepackage{fontspec}
\usepackage{xunicode}
\usepackage{xltxtra}

%\usepackage[utf8]{inputenc}

\usepackage[]{hyperref}
\hypersetup{
    colorlinks=false
}
\urlstyle{same}

% languages
\usepackage{fixlatvian}
\usepackage{polyglossia}
\setdefaultlanguage{latvian}
\setotherlanguages{english,russian}

% fonts
\usepackage{xltxtra}
% \setmainfont[Mapping=tex-text]{Times New Roman}
%\defaultfontfeatures{Scale=MatchLowercase,Mapping=tex-text}

% bibliography
%\usepackage{csquotes}
\usepackage[
    backend=biber,
    style=numeric-comp,
    sorting=none,
    natbib=true,
    url=false,
    doi=true%,
    %eprint=false
]{biblatex}
\addbibresource{bibliography.bib}

% toc
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

%tables
\usepackage{longtable}

%papildus matemātika
\usepackage[showonlyrefs]{mathtools}
\newenvironment{thmenum}
 {\begin{enumerate}[label=\upshape(\arabic*),ref=\thethm(\arabic*)]}
 {\end{enumerate}}
\usepackage{amsmath}

%pseidokodam
%\usepackage[noend]{algpseudocode}
%\usepackage{algpseudocode}
\usepackage[boxed,linesnumbered]{algorithm2e}
\SetAlgorithmName{Algoritms}{}{Algoritmu saraksts}

%main line spacing, kur vajag
\usepackage{setspace}

%lai flushotu floatus
\usepackage{placeins}

%images
\usepackage{graphicx}
\usepackage{float}

%dalīšana kolonnās
\usepackage{multicol}

%saraksti
\usepackage{enumitem}

\fakultate{Datorikas}
\nosaukums{Paredzošā stimulētā mācišanās}
\darbaveids{Maģistra kursa}
\autors{Rihards Krišlauks}
\studapl{rk09006}
\vaditajs{Asoc.prof., Dr. dat. Jānis Zuters}
%\recenzents{Juris Vīksna profesors Dr.sc.comp.}
\vieta{Rīga}
\gads{2015}

\begin{document}
\maketitle

\begin{abstract-lv}
  TODO

\keywords{stimulētā mācīšanās; neironu tīkli; Markova izvēles procesi; nepārtrauktas telpas.}
\end{abstract-lv}
\clearpage

\begin{abstract-en}
  TODO

\keywords{reinforcement learning; artificial neural networks; Markov decision processes; continuous spaces.}
\end{abstract-en}


\tableofcontents

\iffalse
\specnodala{Apzīmējumu saraksts}
\setlength\LTleft{0pt}
\setlength\LTright{0pt}
\begin{longtable}{| c | p{28em} |}
  \hline
  \textbf{Apzīmējums} & \textbf{Atšifrējums}\\ 
  \endhead

  \hline
  $D_X \in \mathbb{N}_+$ & \\ %TODO šis jādefinē arī telpas elementiem
  $S \subseteq \mathbb{R}^{D_S}$ & \\
  $A \subseteq \mathbb{R}^{D_A}$ & \\
  $R:S \times A \times S \rightarrow \mathbb{R}$ & \\
  $T:S \times A \times S \rightarrow [0,1]$ & Apzīmējuma nosaukums \\
  $\pi(s, a)$ &  Apzīmējuma nosaukums 2\\
  \hline
\end{longtable}
\fi

\specnodala{Ievads}
Pēdējā laikā teorētiskajā neirozinātnē plašu piekrišanu sāk iegūt t.s.
paredzošās kodēšanas (predictive coding) teorija, kuras pamattēze ir --
smadzenes ir paredzēšanas mašīnas, tās pastāvīgi cenšas sapārot ienākošos
sensoru signālus ar augsta līmeņa paredzējumiem ar mērķi minimizēt paredzēšanas
kļūdas. Paredzošā kodēšana sniedz vienotu skatījumu uz procesiem, kas ir pamatā
cilvēka apziņai, un piedāvā mehānismu, kas ļauj izskaidrot plašu klāstu ar
neirozinātnē pētītiem cilvēka apziņas fenomeniem \autocite{Clark2013}.

Ideja par smadzenēm kā māšīnām, kas, ņemot vērā pašreizējos novērojumus, cenšas
paredzēt nākotnes novērojumus, ir ļoti pievilcīga no dažādu mašīnmācīšanās
paradigmu skatpunkta. Šis vienkāršais mehānisms šķiet viegli formulējams kā
mašīnmācīšanās problēma, un šķiet it īpaši piemērots, lai to izteiktu kā
stimulētās mācīšanās problēmu.

Stimulētā mācīšanās ir mašīnmācīšanās paradigma, kas formalizē mācīšanos kā
mašīnmācīšanās uzdevumu. Tās pamatā ir ideja par vidi un aģentu, kas tajā
darbojas. Aģenta mērķis ir, ņemot vērā ārēju atalgojuma signālu, veikt darbības
vidē tā, lai maksimizētu saņemto atalgojumu. Šis vienkāršais, bet spēcīgais,
uzstādījums ļauj aprakstīt un risināt ļoti plašu problēmu loku, kur optimālā
rīcības stratēģija nav zināma, bet ir iespējams nodefinēt stāvokli, ko aģentam
būtu jācešas sasniegt. Aģenta ziņā paliek, darbojoties vidē, laika gaitā atrast
optimālo stratēģiju, kas ļautu sasniegt pēc iespējas lielāku atalgojumu. Kā
piemērus šādi risināmām problēmām var minēt orientēšanos labirintā vai
automātisku lidaparāta kontroli.

No augstāk minētā dabīgi seko doma par paredzošās kodēšanas ideju pielietošanu
stimulētās mācīšanās uzdevumu risināšanā. Interesi raisa ideja par vides nākamā
stāvokļa paredzēšanu, ņēmot vērā pašreizējo, un vai tas palīdzētu mācīšanās
procesā. Tas liktu stimulētās mācīšanās aģentam tuvināti iemācīties vides
modeli. Tuvākas izpētes vērts ir jautājums, vai šāds iekšējs modelis palīdzētu
macīšanās procesā.

Šajā darbā tiks pētītas iespējas, izmantot paredzošās kodēšanas idejas stimulētās
mācīšanas uzdevumu risināšanai, kā arī tiek pētītas dažādas citas iespējas ar
papildus informāciju uzlabot mācīšanās ātrumu. Darbs tiek iesākts ar vispārīgu stimulētās
mācīšanās paradigmas apskatu, kur autors galvenokārt pieturas pie izklāsta kas
atrodams \autocite{Krislauks2015}. Tam seko COMBO CACLA algoritma apraksts, un
salīdzinājums ar CACLA algoritmu, uz kā tas ir balstīts. %TODO papildināt, kad
                                %ir vairāk gatavs no satura
%NOTE: pie cacla algoritma jāpastāsta, kas ir tie aspekti, kas padara viņu
%pievilcīgu modifikācijām.
\chapter{CCACLA algoritms}\label{chap:ccacla}
CACLA algoritms izmanto divus neironu tīklus, no kuriem viens aproksimē optimālo
stratēģiju, bet otrs -- stāvokļu vērtības funkciju. Abu neironu tīklu parametri
tiek pielāgoti, tiem savstarpēji mijiedarbojoties algoritma darbības laikā --
stāvokļu vērtības funkcija ir atkarīga no optimālās stratēģijas aproksimācijas,
jo tā nosaka, kādas darbības tiek veiktas katrā stāvoklī, kas laika gaitā
ietekmē stāvokļu vērtību, savukārt optimālās stratēģijas aproksimācija tiek
pielāgota atkarībā no stāvokļu funkcijas izmaiņām, ņemot vērā, vai stratēģijas
noteiktā darbība dotā stāvoklī pēc izpildes palielina stāvokļa vērtību. Šīs
savstarpējās mijiedarbības rezultātā algritms ir spējīgs mācīties, bet rodas
jautājums, vai šādi netiek darīts lieks darbs. Gan stāvokļu vērtības funkcijas
aproksimācijas $V$ gan optimālās stratēģijas funkcijas aproksimācijas $A$ domēns
ir vides stāvokļu telpa $S$. Ir saprātīgi pieņemt, ka abu funkciju vērtības
varētu noteikt līdzīgas pazīmes stāvokļu telpā. Abu attiecīgo neironu tīklu
otrais slānis varētu būt trenēšānas rezultātā iemācījies izejā dot līdzīgus
aktivācijas vienos un tajos pašos stāvokļus, tāpēc rodas jautājums, vai abus
tīklus nav iespējams apvienot.

Skatījumu uz neironu tīkliem kā hierarhiskiem pazīmju izgūšanas rīkiem sniedz
pēdējā laikā lielu popularitāti ieguvusī dziļās mācīšanās paradigma. Tās pamatā
ir ideja, ka daudzos dažādos ar reālo pasauli saistītos domēnos, piemēram, attēlu
vai runas atpazīšānā, dabīgās valodas apstrādē u.c., pētāmos objektus ir
iespējams raksturot ar hierarhisku vairāklīmeņu pazīmju kopumu \autocite{Lecun2015}. Tas ļauj
izmantot vairākļīmeņu neironu tīklus šo pazīmju izgūšanai. %TODO piemērs
Lai arī šajā darbā apskatītajās stimulētās mačīšanās problēmas atāvokļu telpas
nav tik sarežģītas, lai būtu nepieciešamība izmanot dziļus neironu tīklus, tomēr
arī uz sekliem neironu tīkliem var raudzīties kā uz ierīcēm, kas izgūst zema
līmeņa pazīmes, ko pēdējais tīkla līmenis ir iemācījies apstrādāt. Šis skatījums
rada papildus motivāciju pētīt, vai nav iespējams lietderīgi izmantot CACLA
algoritmā izmantoto neironu tīklu apakšējo līmeņu izgūto pazīmju īpatnības.

Šajā nodaļā tiks apskatītas vairākas CACLA algoritma modifikācijas, kuras to
kopīgo īpašību dēļ autors ievieto vienā algoritmu grupā ar kopīgo nosaukumu
Combined CACLA, jeb CCACLA. Visu algoritmu kopīgā iezīme, kas tos atšķir no
iepriekš apskatītā CACLA algoritma ir viena neironu tīkla izmantošana gan
vērtību funkcijas $V$ gan optimālās stratēģijas funkcijas $A$ aproksimācijai.
Tiek apskatīti vairāki šī algoritma paveidi, kas ietver modifikācijas tajā, kāda
informācija tiek izmantota tīkla trenēšanai.

\section{CCACLA pamatalgoritms}
CCACLA vienkāršākais variants, kas vismazāk atšķiras no par pamatu ņemtā CACLA
algoritma, izmanto funkciju $\hat{A}_\Theta:S \rightarrow A$

\chapter{Diskusija}
TODO
\chapter{Secinājumi}
TODO


\printbibliography
\end{document}

%%% Local Variables:
%%% coding: utf-8
%%% mode: latex
%%% TeX-master: t
%%% TeX-engine: xetex
%%% reftex-default-bibliography: ("bibliography.bib")
%%% End:

%%% TeX-command-extra-options: "-shell-escape"